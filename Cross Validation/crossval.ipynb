{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"crossval.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0hSEOEAR4-Rx"},"source":["# **Cross-Validation**\n","\n","**By Philip Blumin and Paul Cucchiara**"]},{"cell_type":"markdown","metadata":{"id":"kKjVyMEnM5YU"},"source":["# **Library Imports**"]},{"cell_type":"code","metadata":{"id":"kU6XylDubIq2"},"source":["import pandas as pd\n","import numpy as np\n","import heapq\n","from numpy import random\n","from sklearn.neighbors import KNeighborsClassifier\n","import scipy.stats\n","from sklearn import metrics"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BeBFaQmtM9Mb"},"source":["# **Method 1 (Wrong method)**"]},{"cell_type":"markdown","metadata":{"id":"9MXN2oLi5LCR"},"source":["In the wrong method, we made random data turning everything into 1s and 0s. We then selected the features based on their correlations to the labels. After the best 100 features were selected, a new feature matrix was created, we broke down the features into 5 different folds, where each fold was a new matrix of 10 samples. Lastly, the K-nearest neighbor was computed for each fold for 50 different datasets. The average accuracy of the folding models are outputted below."]},{"cell_type":"code","metadata":{"id":"UHRn4xuFmH4r","executionInfo":{"status":"ok","timestamp":1601819990145,"user_tz":240,"elapsed":87049,"user":{"displayName":"Paul Melchiore","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_3OQDAN9XjmBHCwEbbZzQBc37e-CYETEf8Vlldg=s64","userId":"01738411429294267759"}},"outputId":"0c33bb72-3e83-4633-8196-82ab49005b67","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#Wrong Method\n","\n","badclassifier = KNeighborsClassifier(n_neighbors = 1, metric = 'minkowski', p = 2)\n","\n","#--------Creating data--------------#\n","\n","tests = []\n","for times in range(0,50):\n","  allData = np.random.random((50,5001)) # data\n","  for i in range(0,len(allData)):\n","    for j in range(0,len(allData[0])):\n","      if allData[i][j] > 0.5:\n","        allData[i][j] = 1\n","      else:\n","        allData[i][j] = 0\n","\n","  featureMatrix = allData[:,0:allData.shape[1]-1] # input\n","  labelMatrix = allData[:,[allData.shape[1]-1]] # output\n","  labelMatrix = np.reshape(labelMatrix, len(labelMatrix))\n","\n","  \n","  wrongModelAccuracy = []\n","  correlationvals = []\n","\n","  #--------Getting 100 best features--------------#\n","\n","  labelMatrix = pd.Series(labelMatrix)\n","  for i in range (0,len(featureMatrix[0])):\n","    column = pd.Series(featureMatrix[:,i])\n","    correlationvals.append(column.corr(labelMatrix))\n","\n","  bestFeatures = heapq.nlargest(100, range(len(correlationvals)), correlationvals.__getitem__)\n","\n","  newFeatures = []\n","  for p in range(0,len(bestFeatures)):\n","    newFeatures.append(featureMatrix[:,bestFeatures[p]])\n","  newFeatures = np.array(newFeatures)\n","  newFeatures = np.transpose(newFeatures)\n","\n","  #--------Splitting data for folds--------------#\n","\n","  firstFold = newFeatures[0:10,:]\n","  secondFold = newFeatures[10:20,:]\n","  thirdFold = newFeatures[20:30,:]\n","  fourthFold = newFeatures[30:40,:]\n","  fifthFold = newFeatures[40:50,:]\n","\n","  firstLabels = labelMatrix[0:10]\n","  secondLabels = labelMatrix[10:20]\n","  thirdLabels = labelMatrix[20:30]\n","  fourthLabels = labelMatrix[30:40]\n","  fifthLabels = labelMatrix[40:50] \n","\n","  #--------K-folds--------------# \n","\n","  for fold in range(1,6):\n","    if fold != 1:\n","      badclassifier.fit(firstFold, firstLabels.ravel())\n","    if fold != 2: \n","      badclassifier.fit(secondFold, secondLabels.ravel())\n","    if fold != 3:\n","      badclassifier.fit(thirdFold, thirdLabels.ravel())\n","    if fold != 4:\n","      badclassifier.fit(fourthFold, fourthLabels.ravel())\n","    if fold != 5:\n","      badclassifier.fit(fifthFold,fifthLabels.ravel())\n","    \n","    if fold == 1:\n","      ypred = badclassifier.predict(firstFold)\n","      wrongModelAccuracy.append(metrics.accuracy_score(firstLabels, ypred))\n","    if fold == 2:\n","      ypred = badclassifier.predict(secondFold)\n","      wrongModelAccuracy.append(metrics.accuracy_score(secondLabels, ypred))\n","    if fold == 3:\n","      ypred = badclassifier.predict(thirdFold)\n","      wrongModelAccuracy.append(metrics.accuracy_score(thirdLabels, ypred))\n","    if fold == 4:\n","      ypred = badclassifier.predict(fourthFold)\n","      wrongModelAccuracy.append(metrics.accuracy_score(fourthLabels, ypred))\n","    if fold == 5:\n","      ypred = badclassifier.predict(fifthFold)\n","      wrongModelAccuracy.append(metrics.accuracy_score(fifthLabels, ypred))\n","  tests.append(wrongModelAccuracy)\n","\n","  \n","print(\"Average Accuracy: \")\n","print(np.sum(tests)/250)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Average Accuracy: \n","0.9612\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RfVd6lte79Lf"},"source":["As we can see, the error for the k-folding is a miniscule 3%. This is far lower than the standard 50% that the data should give us and it concerns us that the models have been overfitted."]},{"cell_type":"markdown","metadata":{"id":"l_cSDiUHNmBu"},"source":["# **Method 2 (correct way)**"]},{"cell_type":"markdown","metadata":{"id":"QMdHZ6lPNrcx"},"source":["The process for getting correct method is identical to the incorrect method with the exception that the whole matrix for features were used.\n"]},{"cell_type":"code","metadata":{"id":"dFfSKTq8sofQ","executionInfo":{"status":"ok","timestamp":1601820002439,"user_tz":240,"elapsed":99331,"user":{"displayName":"Paul Melchiore","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj_3OQDAN9XjmBHCwEbbZzQBc37e-CYETEf8Vlldg=s64","userId":"01738411429294267759"}},"outputId":"fc02e77d-6b21-4a15-b4a7-20e7289d1dbb","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Correct Kfolding\n","\n","classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n","modelAccuracy = []\n","tests = []\n","\n","#--------Creating data--------------#\n","\n","for k in range(0,50):\n","  allData = np.random.random((60,5001)) # data\n","  for i in range(0,len(allData)):\n","    for j in range(0,len(allData[0])):\n","      if allData[i][j] > 0.5:\n","        allData[i][j] = 1\n","      else:\n","        allData[i][j] = 0\n","\n","  #--------Splitting data-------------#\n","\n","  featureMatrix = allData[:,0:allData.shape[1]-1] # input\n","  labelMatrix = allData[:,[allData.shape[1]-1]] # output\n","\n","  firstFold = featureMatrix[0:10,:]\n","  secondFold = featureMatrix[10:20,:]\n","  thirdFold = featureMatrix[20:30,:]\n","  fourthFold = featureMatrix[30:40,:]\n","  fifthFold = featureMatrix[40:50,:]\n","\n","  firstLabels = labelMatrix[0:10]\n","  secondLabels = labelMatrix[10:20]\n","  thirdLabels = labelMatrix[20:30]\n","  fourthLabels = labelMatrix[30:40]\n","  fifthLabels = labelMatrix[40:50]\n","\n","  #--------k-folds--------------#\n","\n","  for fold in range(1,6):\n","    classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n","    if fold != 1:\n","      classifier.fit(firstFold, firstLabels.ravel())\n","    if fold != 2: \n","      classifier.fit(secondFold, secondLabels.ravel())\n","    if fold != 3:\n","      classifier.fit(thirdFold, thirdLabels.ravel())\n","    if fold != 4:\n","      classifier.fit(fourthFold, fourthLabels.ravel())\n","    if fold != 5:\n","      classifier.fit(fifthFold,fifthLabels.ravel())\n","    \n","    if fold == 1:\n","      ypred = classifier.predict(firstFold)\n","      modelAccuracy.append(metrics.accuracy_score(firstLabels, ypred))\n","    if fold == 2:\n","      ypred = classifier.predict(secondFold)\n","      modelAccuracy.append(metrics.accuracy_score(secondLabels, ypred))\n","    if fold == 3:\n","      ypred = classifier.predict(thirdFold)\n","      modelAccuracy.append(metrics.accuracy_score(thirdLabels, ypred))\n","    if fold == 4:\n","      ypred = classifier.predict(fourthFold)\n","      modelAccuracy.append(metrics.accuracy_score(fourthLabels, ypred))\n","    if fold == 5:\n","      ypred = classifier.predict(fifthFold)\n","      modelAccuracy.append(metrics.accuracy_score(fifthLabels, ypred))\n","  tests.append(modelAccuracy)\n","\n","  modelAccuracy = []\n","\n","print(\"Average Accuracy: \")\n","print(np.sum(tests)/250)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Average Accuracy: \n","0.4988\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XqLijXF48UVf"},"source":["Using the correct approach for k-folding, all features are used to form models using K-nearest neighbors. The average accuracy of all of the models is the expected 50% indicating that the models are good."]}]}